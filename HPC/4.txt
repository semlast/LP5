#for vector additon
# Define the CUDA code as a string
cuda_code = """
#include <iostream>
#include <cuda_runtime.h>

using namespace std;

__global__ void vectorAdd(float* a, float* b, float* c, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        c[i] = a[i] + b[i];
    }
}

int main() {
    int n = 1000000; // Vector size
    int size = n * sizeof(float);
    float* h_a, * h_b, * h_c; // Host vectors
    float* d_a, * d_b, * d_c; // Device vectors

    // Allocate memory for host vectors
    h_a = new float[n];
    h_b = new float[n];
    h_c = new float[n];

    // Initialize host vectors
    srand(time(NULL));
    for (int i = 0; i < n; i++) {
        h_a[i] = static_cast<float>(rand()) / RAND_MAX;
        h_b[i] = static_cast<float>(rand()) / RAND_MAX;
    }

    // Allocate memory for device vectors
    cudaMalloc(&d_a, size);
    cudaMalloc(&d_b, size);
    cudaMalloc(&d_c, size);

    // Copy host vectors to device
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // Define grid and block dimensions
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch kernel for vector addition
    vectorAdd<<<numBlocks, blockSize>>>(d_a, d_b, d_c, n);

    // Copy result back to host
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    // Print the first 10 elements of the result vector
    for (int i = 0; i < 10; i++) {
        cout << h_c[i] << " ";
    }
    cout << endl;

    // Free device memory
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    // Free host memory
    delete[] h_a;
    delete[] h_b;
    delete[] h_c;

    return 0;
}

"""
# Write the CUDA code to a file
with open('cuda_code.cu', 'w') as f:
  f.write(cuda_code)
# Compile the CUDA code
!nvcc -o cuda_program cuda_code.cu
# Execute the compiled program
!./cuda_program

# for matrix
# Define the CUDA code as a string
cuda_code = """
#include <iostream>
#include <cuda_runtime.h>
using namespace std;
__global__ void matmul(int* A, int* B, int* C, int N) {
int Row = blockIdx.y * blockDim.y + threadIdx.y;
int Col = blockIdx.x * blockDim.x + threadIdx.x;
if (Row < N && Col < N) {
int Pvalue = 0;
for (int k = 0; k < N; k++) {
Pvalue += A[Row * N + k] * B[k * N + Col];
}
C[Row * N + Col] = Pvalue;
}
}
int main() {
int N = 10;
int size = N * N * sizeof(int);
int* A, * B, * C;
int* dev_A, * dev_B, * dev_C;
cudaMallocHost(&A, size);
cudaMallocHost(&B, size);
cudaMallocHost(&C, size);
cudaMalloc(&dev_A, size);
cudaMalloc(&dev_B, size);
cudaMalloc(&dev_C, size);
// Initialize matrices A and B
for (int i = 0; i < N; i++) {
for (int j = 0; j < N; j++) {
A[i * N + j] = i * N + j;
B[i * N + j] = j * N + i;
}
}
cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);
cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);
dim3 dimBlock(16, 16);
dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);
matmul<<<dimGrid, dimBlock>>>(dev_A, dev_B, dev_C, N);
cudaDeviceSynchronize(); // Ensure kernel execution is complete
cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);
// Print the result
for (int i = 0; i < 10; i++) {
for (int j = 0; j < 10; j++) {
std::cout << C[i * N + j] << " ";
}
std::cout << std::endl;
}
// Free memory
cudaFree(dev_A);
cudaFree(dev_B);
cudaFree(dev_C);
cudaFreeHost(A);
cudaFreeHost(B);
cudaFreeHost(C);
return 0;
}
"""
# Write the CUDA code to a file
with open('cuda_code.cu', 'w') as f:
  f.write(cuda_code)
# Compile the CUDA code
!nvcc -o cuda_program cuda_code.cu
# Execute the compiled program
!./cuda_program
